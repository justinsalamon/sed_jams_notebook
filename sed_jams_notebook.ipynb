{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sed_jams_notebook\n",
    "\n",
    "This notebook shows how to compute the segment-based F1 score for sound event detection from 2 JAMS files containing sound event annotations (one refernce, one estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the things we need\n",
    "import jams\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's start by loading the reference and estimate JAMS files\n",
    "ref_file = 'data/sed_ref.jams'\n",
    "est_file = 'data/sed_est.jams'\n",
    "\n",
    "ref_jam = jams.load(ref_file)\n",
    "est_jam = jams.load(est_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>value</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:08.719542</td>\n",
       "      <td>vehicle: engine</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:04.087710</td>\n",
       "      <td>00:00:04.631832</td>\n",
       "      <td>church bell: ring</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:06.665484</td>\n",
       "      <td>00:00:01.108647</td>\n",
       "      <td>human: voice</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time        duration              value  confidence\n",
       "0        00:00:00 00:00:08.719542    vehicle: engine         1.0\n",
       "1 00:00:04.087710 00:00:04.631832  church bell: ring         1.0\n",
       "2 00:00:06.665484 00:00:01.108647       human: voice         1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's examine the reference labels:\n",
    "ref_jam.annotations[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>value</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:02.500000</td>\n",
       "      <td>00:00:05.500000</td>\n",
       "      <td>vehicle: engine</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:04</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>church bell: ring</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:06.665484</td>\n",
       "      <td>00:00:01.108647</td>\n",
       "      <td>human: voice</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:08</td>\n",
       "      <td>00:00:00.500000</td>\n",
       "      <td>alien</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time        duration              value  confidence\n",
       "0 00:00:02.500000 00:00:05.500000    vehicle: engine         1.0\n",
       "1        00:00:04        00:00:03  church bell: ring         1.0\n",
       "2 00:00:06.665484 00:00:01.108647       human: voice         1.0\n",
       "3        00:00:08 00:00:00.500000              alien         1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's examine the estimate labels:\n",
    "est_jam.annotations[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.719542\n",
      "8.719542\n"
     ]
    }
   ],
   "source": [
    "# Both files correspondin to a clip of roughly 9 seconds:\n",
    "ref_dur = ref_jam.file_metadata.duration\n",
    "est_dur = est_jam.file_metadata.duration\n",
    "print(ref_dur)\n",
    "print(est_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# create a grid based on a chosen segment length:\n",
    "segment_length = 1 # 1 second\n",
    "grid_size = int(np.ceil(max(ref_dur, est_dur) / float(segment_length)))\n",
    "print(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now lets create label grids for the refernce and estimatze. Each item in the label grid will \n",
    "# be a list containing all the labels that overlap with the corresponding time segment\n",
    "ref_grid = []\n",
    "est_grid = []\n",
    "for _ in range(grid_size):\n",
    "    ref_grid.append([])\n",
    "    est_grid.append([])\n",
    "\n",
    "# This is not necessarily the most efficient way to do this, but at least it's correct...\n",
    "\n",
    "# Slice reference events into segments\n",
    "for ind, event in ref_jam.annotations[0].data.iterrows():\n",
    "    \n",
    "#     print(ind)\n",
    "#     print(event)\n",
    "\n",
    "    # get event start/end times\n",
    "    event_start = event['time'].total_seconds()\n",
    "    event_end = event['time'].total_seconds() + event['duration'].total_seconds()\n",
    "    \n",
    "    # find first and last segments that overlap with the event\n",
    "    # note the integer division operator used here!\n",
    "    first_seg_ind = int(event_start // segment_length)\n",
    "    last_seg_ind = int(event_end // segment_length)\n",
    "                    \n",
    "    # Handle corner case where event ends exaclty on grid boundary\n",
    "    if event_end % segment_length == 0:\n",
    "        last_seg_ind -= 1\n",
    "    \n",
    "#     print(first_seg_ind)\n",
    "#     print(last_seg_ind)\n",
    "    \n",
    "    # add label to all overlapping segments\n",
    "    for s in range(first_seg_ind, last_seg_ind+1):\n",
    "        ref_grid[s].append(event['value'])\n",
    "\n",
    "# Slice estimate events into segments\n",
    "for _, event in est_jam.annotations[0].data.iterrows():\n",
    "\n",
    "    # get event start/end times\n",
    "    event_start = event['time'].total_seconds()\n",
    "    event_end = event['time'].total_seconds() + event['duration'].total_seconds()\n",
    "    \n",
    "    # find first and last segments that overlap with the event\n",
    "    # note the integer division operator used here!\n",
    "    first_seg_ind = int(event_start // segment_length)\n",
    "    last_seg_ind = int(event_end // segment_length)\n",
    "    \n",
    "    # Handle corner case where event ends exaclty on grid boundary\n",
    "    if event_end % segment_length == 0:\n",
    "        last_seg_ind -= 1\n",
    "    \n",
    "    # add label to all overlapping segments\n",
    "    for seg in range(first_seg_ind, last_seg_ind+1):\n",
    "        est_grid[seg].append(event['value'])\n",
    "        \n",
    "# Ensure each label list is unique\n",
    "for i in range(grid_size):\n",
    "    ref_grid[i] = np.unique(ref_grid[i]).tolist()\n",
    "    est_grid[i] = np.unique(est_grid[i]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'vehicle: engine'],\n",
       " [u'vehicle: engine'],\n",
       " [u'vehicle: engine'],\n",
       " [u'vehicle: engine'],\n",
       " [u'church bell: ring', u'vehicle: engine'],\n",
       " [u'church bell: ring', u'vehicle: engine'],\n",
       " [u'church bell: ring', u'human: voice', u'vehicle: engine'],\n",
       " [u'church bell: ring', u'human: voice', u'vehicle: engine'],\n",
       " [u'church bell: ring', u'vehicle: engine']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the reference label grid:\n",
    "ref_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [u'vehicle: engine'],\n",
       " [u'vehicle: engine'],\n",
       " [u'church bell: ring', u'vehicle: engine'],\n",
       " [u'church bell: ring', u'vehicle: engine'],\n",
       " [u'church bell: ring', u'human: voice', u'vehicle: engine'],\n",
       " [u'human: voice', u'vehicle: engine'],\n",
       " [u'alien']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the estimate label grid:\n",
    "est_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now we can easily compute the metrics for each segment:\n",
    "\n",
    "# Total scores\n",
    "TP_tot = 0\n",
    "FP_tot = 0\n",
    "FN_tot = 0\n",
    "\n",
    "for seg_ref_labels, seg_est_labels in zip(ref_grid, est_grid):\n",
    "    \n",
    "    # True positives are labels that appear in both lists\n",
    "    TP = len(np.intersect1d(seg_ref_labels, seg_est_labels))\n",
    "    # False positives are labels that appear in est but not in ref\n",
    "    FP = len(seg_est_labels) - TP\n",
    "    # False negatives are labels that appear in ref but not in est\n",
    "    FN = len(seg_ref_labels) - TP\n",
    "    \n",
    "    # Add the segment scores to the total scores\n",
    "    TP_tot += TP\n",
    "    FP_tot += FP\n",
    "    FN_tot += FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785714285714\n"
     ]
    }
   ],
   "source": [
    "# Now we can compute the gloval F1 measure:\n",
    "F1 = 2*TP_tot / float(2*TP_tot + FP_tot + FN_tot)\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All combined into a single function\n",
    "Now we're going to package all this into a single function that takes 2 JAMS filepaths and the desired segment duration and computes everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_f1(ref_jams_path, est_jams_path, segment_length=1):\n",
    "    \n",
    "    # Let's start by loading the reference and estimate JAMS files\n",
    "    ref_file = '/Users/justin/Downloads/sed_demo/sed_ref.jams'\n",
    "    est_file = '/Users/justin/Downloads/sed_demo/sed_est.jams'\n",
    "\n",
    "    ref_jam = jams.load(ref_file)\n",
    "    est_jam = jams.load(est_file)\n",
    "    \n",
    "    # create a grid based on a chosen segment length:\n",
    "    grid_size = int(np.ceil(max(ref_dur, est_dur) / float(segment_length)))\n",
    "    \n",
    "    # Now lets create label grids for the refernce and estimatze. Each item in the label grid will \n",
    "    # be a list containing all the labels that overlap with the corresponding time segment\n",
    "    ref_grid = []\n",
    "    est_grid = []\n",
    "    for _ in range(grid_size):\n",
    "        ref_grid.append([])\n",
    "        est_grid.append([])\n",
    "\n",
    "    # This is not necessarily the most efficient way to do this, but at least it's correct...\n",
    "\n",
    "    # Slice reference events into segments\n",
    "    for _, event in ref_jam.annotations[0].data.iterrows():\n",
    "\n",
    "        # get event start/end times\n",
    "        event_start = event['time'].total_seconds()\n",
    "        event_end = event['time'].total_seconds() + event['duration'].total_seconds()\n",
    "\n",
    "        # find first and last segments that overlap with the event\n",
    "        # note the integer division operator used here!\n",
    "        first_seg_ind = int(event_start // segment_length)\n",
    "        last_seg_ind = int(event_end // segment_length)\n",
    "        \n",
    "        # Handle corner case where event ends exaclty on grid boundary\n",
    "        if event_end % segment_length == 0:\n",
    "            last_seg_ind -= 1\n",
    "\n",
    "        # add label to all overlapping segments\n",
    "        for s in range(first_seg_ind, last_seg_ind+1):\n",
    "            ref_grid[s].append(event['value'])\n",
    "\n",
    "    # Slice estimate events into segments\n",
    "    for _, event in est_jam.annotations[0].data.iterrows():\n",
    "\n",
    "        # get event start/end times\n",
    "        event_start = event['time'].total_seconds()\n",
    "        event_end = event['time'].total_seconds() + event['duration'].total_seconds()\n",
    "\n",
    "        # find first and last segments that overlap with the event\n",
    "        # note the integer division operator used here!\n",
    "        first_seg_ind = int(event_start // segment_length)\n",
    "        last_seg_ind = int(event_end // segment_length)\n",
    "        \n",
    "        # Handle corner case where event ends exaclty on grid boundary\n",
    "        if event_end % segment_length == 0:\n",
    "            last_seg_ind -= 1\n",
    "\n",
    "        # add label to all overlapping segments\n",
    "        for seg in range(first_seg_ind, last_seg_ind+1):\n",
    "            est_grid[seg].append(event['value'])\n",
    "\n",
    "    # Ensure each label list is unique\n",
    "    for seg in range(grid_size):\n",
    "        ref_grid[seg] = np.unique(ref_grid[seg]).tolist()\n",
    "        est_grid[seg] = np.unique(est_grid[seg]).tolist()\n",
    "        \n",
    "    # now we can easily compute the metrics for each segment:\n",
    "    # Total scores\n",
    "    TP_tot = 0\n",
    "    FP_tot = 0\n",
    "    FN_tot = 0\n",
    "\n",
    "    for seg_ref_labels, seg_est_labels in zip(ref_grid, est_grid):\n",
    "\n",
    "        # True positives are labels that appear in both lists\n",
    "        TP = len(np.intersect1d(seg_ref_labels, seg_est_labels))\n",
    "        # False positives are labels that appear in est but not in ref\n",
    "        FP = len(seg_est_labels) - TP\n",
    "        # False negatives are labels that appear in ref but not in est\n",
    "        FN = len(seg_ref_labels) - TP\n",
    "\n",
    "        # Add the segment scores to the total scores\n",
    "        TP_tot += TP\n",
    "        FP_tot += FP\n",
    "        FN_tot += FN\n",
    "        \n",
    "    # Now we can compute the gloval F1 measure:\n",
    "    F1 = 2*TP_tot / float(2*TP_tot + FP_tot + FN_tot)\n",
    "    \n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun time!\n",
    "Now we can easily evaluate different references against differences estimates, as well as try different segment lengths and see how they influence the results. Remember that the segment length basically defines how lenient we are about matching event onsets/offsets - the default of 1s means they can be at most 1s from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the default 1s segment\n",
    "segment_f1(ref_file, est_file, segment_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we use a larger segment, we become more lenient and the score will go up\n",
    "segment_f1(ref_file, est_file, segment_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we use a smaller segment, we become more strict and the score will go down\n",
    "segment_f1(ref_file, est_file, segment_length=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7754770604953309"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we use a really small segment, the evaluation is basically frame-based:\n",
    "segment_f1(ref_file, est_file, segment_length=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all folks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
